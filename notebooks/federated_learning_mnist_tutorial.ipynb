{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Federated Learning with MNIST - Complete Tutorial\n\nThis notebook demonstrates how to implement Federated Learning using the **Flower** framework with the MNIST dataset.\n\n## ‚ö° FAST MODE ENABLED\nThis notebook is configured for **quick testing** (~5-10 minutes on Kaggle).  \nSettings: 5 clients, 3 rounds, 3 clients per round.\n\nTo run full experiments, modify Cell 3 with:\n- `NUM_CLIENTS = 10`\n- `NUM_ROUNDS = 10`\n- `CLIENTS_PER_ROUND = 5`\n\n## What you'll learn:\n1. How to partition a dataset for federated learning (IID vs Non-IID)\n2. How to create FL clients and server\n3. How to run a federated learning simulation\n4. How to visualize data distribution across clients\n\n**Author:** Generated for Federated Learning Tutorial  \n**Platform:** Kaggle / Google Colab  \n**Framework:** Flower (flwr)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 1: Install Dependencies\n",
    "Run this cell first to install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Flower and Flower Datasets\n",
    "!pip install -q flwr flwr-datasets torch torchvision matplotlib seaborn\n",
    "\n",
    "print(\"Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from collections import OrderedDict\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Flower imports\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner, DirichletPartitioner\n",
    "\n",
    "# Check versions\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Flower version: {fl.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Cell 3: Configuration (‚ö° FAST MODE)\n\nThese settings are optimized for quick testing (~5-10 minutes on Kaggle).\n\n| Parameter | Fast Mode | Full Experiment |\n|-----------|-----------|-----------------|\n| NUM_CLIENTS | 5 | 10 |\n| NUM_ROUNDS | 3 | 10 |\n| CLIENTS_PER_ROUND | 3 | 5 |\n| BATCH_SIZE | 64 | 32 |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CONFIGURATION - FAST MODE (for quick testing on Kaggle ~5-10 minutes)\n# =============================================================================\n# To run full experiments later, increase these values:\n#   NUM_CLIENTS=10, NUM_ROUNDS=10, CLIENTS_PER_ROUND=5\n\n# Federated Learning Settings (REDUCED FOR FAST TESTING)\nNUM_CLIENTS = 5           # Number of clients (simulated devices) [was 10]\nNUM_ROUNDS = 3            # Number of federated learning rounds [was 5]\nCLIENTS_PER_ROUND = 3     # Number of clients selected per round [was 5]\n\n# Data Partitioning Settings\nPARTITION_TYPE = \"dirichlet\"  # Options: \"iid\" or \"dirichlet\"\nDIRICHLET_ALPHA = 0.5         # Lower = more non-IID (only used if PARTITION_TYPE=\"dirichlet\")\n\n# Training Settings\nBATCH_SIZE = 64           # Larger batch = faster training [was 32]\nLOCAL_EPOCHS = 1          # Number of local epochs per client per round\nLEARNING_RATE = 0.01\n\n# Random seed for reproducibility\nSEED = 42\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\n\nprint(\"=\"*60)\nprint(\"‚ö° FAST MODE CONFIGURATION (for quick pipeline testing)\")\nprint(\"=\"*60)\nprint(f\"  - Number of clients: {NUM_CLIENTS}\")\nprint(f\"  - Clients per round: {CLIENTS_PER_ROUND}\")\nprint(f\"  - Number of rounds: {NUM_ROUNDS}\")\nprint(f\"  - Partition type: {PARTITION_TYPE}\")\nif PARTITION_TYPE == \"dirichlet\":\n    print(f\"  - Dirichlet alpha: {DIRICHLET_ALPHA}\")\nprint(f\"  - Local epochs: {LOCAL_EPOCHS}\")\nprint(f\"  - Batch size: {BATCH_SIZE}\")\nprint(\"=\"*60)\nprint(\"Estimated time on Kaggle: 5-10 minutes\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 4: Create Federated Dataset\n",
    "\n",
    "This is the KEY difference from centralized learning!\n",
    "\n",
    "Instead of one dataset, we partition MNIST into multiple client datasets:\n",
    "- **IID**: Each client gets a random, uniform sample (all classes represented equally)\n",
    "- **Non-IID (Dirichlet)**: Each client gets a skewed distribution (some classes overrepresented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitioner based on configuration\n",
    "if PARTITION_TYPE == \"iid\":\n",
    "    partitioner = IidPartitioner(num_partitions=NUM_CLIENTS)\n",
    "    print(f\"Using IID partitioning with {NUM_CLIENTS} partitions\")\n",
    "else:\n",
    "    partitioner = DirichletPartitioner(\n",
    "        num_partitions=NUM_CLIENTS,\n",
    "        partition_by=\"label\",\n",
    "        alpha=DIRICHLET_ALPHA,\n",
    "        min_partition_size=100,\n",
    "        self_balancing=True\n",
    "    )\n",
    "    print(f\"Using Dirichlet partitioning with alpha={DIRICHLET_ALPHA}\")\n",
    "\n",
    "# Create FederatedDataset - this downloads MNIST automatically!\n",
    "print(\"\\nDownloading and partitioning MNIST dataset...\")\n",
    "fds = FederatedDataset(\n",
    "    dataset=\"mnist\",\n",
    "    partitioners={\"train\": partitioner}\n",
    ")\n",
    "\n",
    "print(\"Dataset ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 5: Visualize Data Distribution Across Clients\n",
    "\n",
    "This visualization shows how data is distributed across clients.\n",
    "- **IID**: All clients have similar distributions\n",
    "- **Non-IID**: Each client has a different, skewed distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data_distribution(fds, num_clients):\n",
    "    \"\"\"Visualize the label distribution across all clients.\"\"\"\n",
    "    \n",
    "    # Collect label counts for each client\n",
    "    client_label_counts = []\n",
    "    \n",
    "    print(\"Data distribution across clients:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for client_id in range(num_clients):\n",
    "        partition = fds.load_partition(client_id, \"train\")\n",
    "        labels = [sample[\"label\"] for sample in partition]\n",
    "        \n",
    "        # Count labels\n",
    "        label_counts = np.zeros(10)\n",
    "        for label in labels:\n",
    "            label_counts[label] += 1\n",
    "        \n",
    "        client_label_counts.append(label_counts)\n",
    "        \n",
    "        # Print summary\n",
    "        present_labels = [i for i in range(10) if label_counts[i] > 0]\n",
    "        print(f\"Client {client_id:2d}: {len(labels):5d} samples | \"\n",
    "              f\"Classes present: {present_labels}\")\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Heatmap\n",
    "    data_matrix = np.array(client_label_counts)\n",
    "    sns.heatmap(data_matrix, annot=True, fmt='.0f', cmap='YlOrRd',\n",
    "                xticklabels=[str(i) for i in range(10)],\n",
    "                yticklabels=[f'Client {i}' for i in range(num_clients)],\n",
    "                ax=axes[0])\n",
    "    axes[0].set_xlabel('Digit Label')\n",
    "    axes[0].set_ylabel('Client')\n",
    "    axes[0].set_title(f'Label Distribution Across Clients\\n({PARTITION_TYPE.upper()} Partitioning)')\n",
    "    \n",
    "    # Stacked bar chart\n",
    "    data_normalized = data_matrix / data_matrix.sum(axis=1, keepdims=True)\n",
    "    bottom = np.zeros(num_clients)\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "    \n",
    "    for label in range(10):\n",
    "        axes[1].bar(range(num_clients), data_normalized[:, label], \n",
    "                   bottom=bottom, label=str(label), color=colors[label])\n",
    "        bottom += data_normalized[:, label]\n",
    "    \n",
    "    axes[1].set_xlabel('Client ID')\n",
    "    axes[1].set_ylabel('Proportion')\n",
    "    axes[1].set_title('Normalized Label Distribution')\n",
    "    axes[1].legend(title='Digit', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[1].set_xticks(range(num_clients))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return client_label_counts\n",
    "\n",
    "# Visualize the distribution\n",
    "client_distributions = visualize_data_distribution(fds, NUM_CLIENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 6: Define the Neural Network Model\n",
    "\n",
    "A simple CNN for MNIST classification. This same model architecture is used by all clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    \"\"\"Simple CNN for MNIST classification.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Ensure input is 4D: (batch, channels, height, width)\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(1)\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 28x28 -> 14x14\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 14x14 -> 7x7\n",
    "        x = self.dropout1(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Test the model\n",
    "model = MNISTNet().to(DEVICE)\n",
    "print(f\"Model architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 7: Data Loading Functions\n",
    "\n",
    "Functions to load and preprocess data for each client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transforms(batch):\n",
    "    \"\"\"Apply transformations to a batch of data.\"\"\"\n",
    "    transforms = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize((0.1307,), (0.3081,))  # MNIST mean and std\n",
    "    ])\n",
    "    batch[\"image\"] = [transforms(img) for img in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "\n",
    "def load_client_data(partition_id: int) -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Load training and validation data for a specific client.\n",
    "    \n",
    "    Args:\n",
    "        partition_id: The client ID (0 to NUM_CLIENTS-1)\n",
    "    \n",
    "    Returns:\n",
    "        trainloader, valloader: DataLoader objects for training and validation\n",
    "    \"\"\"\n",
    "    # Load the partition for this client\n",
    "    partition = fds.load_partition(partition_id, \"train\")\n",
    "    \n",
    "    # Split into train (80%) and validation (20%)\n",
    "    partition = partition.train_test_split(test_size=0.2, seed=SEED)\n",
    "    \n",
    "    # Apply transforms\n",
    "    partition = partition.with_transform(apply_transforms)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    trainloader = DataLoader(\n",
    "        partition[\"train\"], \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    valloader = DataLoader(\n",
    "        partition[\"test\"], \n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    return trainloader, valloader\n",
    "\n",
    "\n",
    "# Test loading data for client 0\n",
    "print(\"Testing data loading for Client 0...\")\n",
    "train_loader, val_loader = load_client_data(0)\n",
    "print(f\"  Training batches: {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "\n",
    "# Check a batch\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"  Batch image shape: {batch['image'].shape}\")\n",
    "print(f\"  Batch label shape: {batch['label'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 8: Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, trainloader: DataLoader, epochs: int) -> float:\n",
    "    \"\"\"\n",
    "    Train the model on the local data.\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network model\n",
    "        trainloader: DataLoader for training data\n",
    "        epochs: Number of local epochs\n",
    "    \n",
    "    Returns:\n",
    "        Average training loss\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch in trainloader:\n",
    "            images = batch[\"image\"].to(DEVICE)\n",
    "            labels = batch[\"label\"].to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, valloader: DataLoader) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the model on validation data.\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network model\n",
    "        valloader: DataLoader for validation data\n",
    "    \n",
    "    Returns:\n",
    "        loss: Average validation loss\n",
    "        accuracy: Validation accuracy\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in valloader:\n",
    "            images = batch[\"image\"].to(DEVICE)\n",
    "            labels = batch[\"label\"].to(DEVICE)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    avg_loss = total_loss / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "print(\"Training and evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 9: Define the Flower Client\n",
    "\n",
    "The Flower Client is the core component that runs on each \"device\".\n",
    "It handles:\n",
    "1. Receiving model parameters from the server\n",
    "2. Training on local data\n",
    "3. Sending updated parameters back to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    \"\"\"\n",
    "    Flower client for federated learning.\n",
    "    \n",
    "    Each client:\n",
    "    1. Receives global model parameters from server\n",
    "    2. Trains on its local (private) data\n",
    "    3. Sends updated parameters back to server\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, partition_id: int):\n",
    "        self.partition_id = partition_id\n",
    "        self.model = MNISTNet().to(DEVICE)\n",
    "        self.trainloader, self.valloader = load_client_data(partition_id)\n",
    "    \n",
    "    def get_parameters(self, config):\n",
    "        \"\"\"Return the current model parameters.\"\"\"\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "    \n",
    "    def set_parameters(self, parameters):\n",
    "        \"\"\"Set model parameters received from the server.\"\"\"\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "    \n",
    "    def fit(self, parameters, config):\n",
    "        \"\"\"\n",
    "        Train the model on local data.\n",
    "        \n",
    "        This is called by the server during each round.\n",
    "        \"\"\"\n",
    "        # Update local model with global parameters\n",
    "        self.set_parameters(parameters)\n",
    "        \n",
    "        # Train on local data\n",
    "        avg_loss = train(self.model, self.trainloader, LOCAL_EPOCHS)\n",
    "        \n",
    "        # Return updated parameters and training info\n",
    "        return (\n",
    "            self.get_parameters(config={}),\n",
    "            len(self.trainloader.dataset),\n",
    "            {\"loss\": avg_loss, \"partition_id\": self.partition_id}\n",
    "        )\n",
    "    \n",
    "    def evaluate(self, parameters, config):\n",
    "        \"\"\"\n",
    "        Evaluate the model on local validation data.\n",
    "        \"\"\"\n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy = evaluate(self.model, self.valloader)\n",
    "        \n",
    "        return (\n",
    "            loss,\n",
    "            len(self.valloader.dataset),\n",
    "            {\"accuracy\": accuracy, \"partition_id\": self.partition_id}\n",
    "        )\n",
    "\n",
    "\n",
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client for the given client ID.\"\"\"\n",
    "    return FlowerClient(partition_id=int(cid))\n",
    "\n",
    "\n",
    "print(\"Flower client defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 10: Define Metrics Aggregation\n",
    "\n",
    "Functions to aggregate metrics (like accuracy) from all clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    \"\"\"\n",
    "    Aggregate accuracy metrics from all clients using weighted average.\n",
    "    \n",
    "    Args:\n",
    "        metrics: List of (num_examples, metrics_dict) tuples from each client\n",
    "    \n",
    "    Returns:\n",
    "        Aggregated metrics dictionary\n",
    "    \"\"\"\n",
    "    # Multiply accuracy by number of examples\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "    \n",
    "    # Weighted average\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "\n",
    "# Store metrics for plotting\n",
    "round_metrics = {\n",
    "    \"round\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"loss\": []\n",
    "}\n",
    "\n",
    "print(\"Metrics aggregation defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Cell 11: Run Federated Learning Simulation ‚è±Ô∏è\n\n**Estimated time: 3-5 minutes** (Fast Mode)\n\nThis is where the magic happens! The simulation:\n1. Initializes a global model on the server\n2. For each round:\n   - Server sends model to selected clients\n   - Clients train on their local data\n   - Clients send updated models back\n   - Server aggregates updates (FedAvg)\n3. Repeat until convergence"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import time\n\n# Define the federated learning strategy\nstrategy = fl.server.strategy.FedAvg(\n    fraction_fit=CLIENTS_PER_ROUND / NUM_CLIENTS,  # Fraction of clients for training\n    fraction_evaluate=0.5,  # Fraction of clients for evaluation\n    min_fit_clients=CLIENTS_PER_ROUND,  # Minimum clients for training\n    min_evaluate_clients=2,  # Minimum clients for evaluation\n    min_available_clients=NUM_CLIENTS,  # Minimum available clients\n    evaluate_metrics_aggregation_fn=weighted_average,  # Aggregate evaluation metrics\n)\n\nprint(\"=\"*60)\nprint(\"‚ö° STARTING FEDERATED LEARNING SIMULATION (FAST MODE)\")\nprint(\"=\"*60)\nprint(f\"\\nConfiguration:\")\nprint(f\"  - Total clients: {NUM_CLIENTS}\")\nprint(f\"  - Clients per round: {CLIENTS_PER_ROUND}\")\nprint(f\"  - Total rounds: {NUM_ROUNDS}\")\nprint(f\"  - Partition type: {PARTITION_TYPE}\")\nprint(f\"  - Local epochs: {LOCAL_EPOCHS}\")\nprint(\"\\n\" + \"=\"*60)\nprint(\"Starting... (this will take ~3-5 minutes)\")\nprint(\"=\"*60 + \"\\n\")\n\n# Track time\nstart_time = time.time()\n\n# Run the simulation\nhistory = fl.simulation.start_simulation(\n    client_fn=client_fn,\n    num_clients=NUM_CLIENTS,\n    config=fl.server.ServerConfig(num_rounds=NUM_ROUNDS),\n    strategy=strategy,\n    client_resources={\"num_cpus\": 1, \"num_gpus\": 0.1 if torch.cuda.is_available() else 0.0},\n)\n\n# Calculate elapsed time\nelapsed_time = time.time() - start_time\nminutes = int(elapsed_time // 60)\nseconds = int(elapsed_time % 60)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"‚úÖ SIMULATION COMPLETE!\")\nprint(f\"‚è±Ô∏è  Total time: {minutes}m {seconds}s\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 12: Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics from history\n",
    "print(\"\\nTraining History:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Get distributed (federated) evaluation accuracy\n",
    "if history.metrics_distributed:\n",
    "    rounds = [r for r, _ in history.metrics_distributed[\"accuracy\"]]\n",
    "    accuracies = [acc for _, acc in history.metrics_distributed[\"accuracy\"]]\n",
    "    \n",
    "    for r, acc in zip(rounds, accuracies):\n",
    "        print(f\"Round {r}: Accuracy = {acc:.4f} ({acc*100:.2f}%)\")\n",
    "\n",
    "# Get losses\n",
    "if history.losses_distributed:\n",
    "    losses = [loss for _, loss in history.losses_distributed]\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "if history.metrics_distributed and \"accuracy\" in history.metrics_distributed:\n",
    "    axes[0].plot(rounds, accuracies, 'b-o', linewidth=2, markersize=8)\n",
    "    axes[0].set_xlabel('Round')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].set_title('Federated Learning Accuracy')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_ylim([0, 1])\n",
    "\n",
    "# Plot loss\n",
    "if history.losses_distributed:\n",
    "    loss_rounds = [r for r, _ in history.losses_distributed]\n",
    "    axes[1].plot(loss_rounds, losses, 'r-o', linewidth=2, markersize=8)\n",
    "    axes[1].set_xlabel('Round')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].set_title('Federated Learning Loss')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final results\n",
    "if accuracies:\n",
    "    print(f\"\\n\" + \"=\"*40)\n",
    "    print(f\"FINAL RESULTS\")\n",
    "    print(f\"=\"*40)\n",
    "    print(f\"Final Accuracy: {accuracies[-1]*100:.2f}%\")\n",
    "    print(f\"Best Accuracy:  {max(accuracies)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 13: Compare IID vs Non-IID (Optional)\n",
    "\n",
    "Run this cell to see how different partitioning strategies affect training.\n",
    "This demonstrates the challenge of non-IID data in federated learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def run_experiment(partition_type: str, alpha: float = 0.5, num_rounds: int = 3):\n    \"\"\"\n    Run a federated learning experiment with specified partitioning.\n    \n    Args:\n        partition_type: \"iid\" or \"dirichlet\"\n        alpha: Dirichlet concentration parameter (only used if partition_type=\"dirichlet\")\n        num_rounds: Number of FL rounds\n    \n    Returns:\n        History object with training metrics\n    \"\"\"\n    global fds\n    \n    # Create partitioner\n    if partition_type == \"iid\":\n        partitioner = IidPartitioner(num_partitions=NUM_CLIENTS)\n    else:\n        partitioner = DirichletPartitioner(\n            num_partitions=NUM_CLIENTS,\n            partition_by=\"label\",\n            alpha=alpha,\n            min_partition_size=100,\n            self_balancing=True\n        )\n    \n    # Create new FederatedDataset\n    fds = FederatedDataset(\n        dataset=\"mnist\",\n        partitioners={\"train\": partitioner}\n    )\n    \n    # Run simulation\n    strategy = fl.server.strategy.FedAvg(\n        fraction_fit=CLIENTS_PER_ROUND / NUM_CLIENTS,\n        fraction_evaluate=0.5,\n        min_fit_clients=CLIENTS_PER_ROUND,\n        min_evaluate_clients=2,\n        min_available_clients=NUM_CLIENTS,\n        evaluate_metrics_aggregation_fn=weighted_average,\n    )\n    \n    history = fl.simulation.start_simulation(\n        client_fn=client_fn,\n        num_clients=NUM_CLIENTS,\n        config=fl.server.ServerConfig(num_rounds=num_rounds),\n        strategy=strategy,\n        client_resources={\"num_cpus\": 1, \"num_gpus\": 0.1 if torch.cuda.is_available() else 0.0},\n    )\n    \n    return history\n\n\n# =============================================================================\n# OPTIONAL: Run comparison experiments\n# =============================================================================\n# These are commented out by default to save time.\n# Uncomment to compare IID vs Non-IID performance (~10 min total)\n\n# print(\"Running IID experiment...\")\n# history_iid = run_experiment(\"iid\", num_rounds=3)\n# iid_acc = [acc for _, acc in history_iid.metrics_distributed[\"accuracy\"]]\n# print(f\"IID Final Accuracy: {iid_acc[-1]*100:.2f}%\")\n\n# print(\"\\nRunning Non-IID (alpha=0.1) experiment...\")\n# history_noniid = run_experiment(\"dirichlet\", alpha=0.1, num_rounds=3)\n# noniid_acc = [acc for _, acc in history_noniid.metrics_distributed[\"accuracy\"]]\n# print(f\"Non-IID Final Accuracy: {noniid_acc[-1]*100:.2f}%\")\n\nprint(\"Comparison function defined!\")\nprint(\"Uncomment the experiment lines above to run IID vs Non-IID comparison.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 14: Examine a Single Client's Training (Educational)\n",
    "\n",
    "This cell shows what happens on a single client during federated learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Examining Client 0's local training...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create a client\n",
    "client = FlowerClient(partition_id=0)\n",
    "\n",
    "# Show client's data distribution\n",
    "partition = fds.load_partition(0, \"train\")\n",
    "labels = [sample[\"label\"] for sample in partition]\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "print(f\"\\nClient 0 data distribution:\")\n",
    "for label, count in zip(unique, counts):\n",
    "    bar = \"‚ñà\" * (count // 50)\n",
    "    print(f\"  Digit {label}: {count:4d} samples {bar}\")\n",
    "\n",
    "# Train for a few epochs and show progress\n",
    "print(f\"\\nTraining Client 0 for {LOCAL_EPOCHS} epoch(s)...\")\n",
    "model = MNISTNet().to(DEVICE)\n",
    "trainloader, valloader = load_client_data(0)\n",
    "\n",
    "# Evaluate before training\n",
    "loss_before, acc_before = evaluate(model, valloader)\n",
    "print(f\"  Before training: Loss={loss_before:.4f}, Accuracy={acc_before*100:.2f}%\")\n",
    "\n",
    "# Train\n",
    "train_loss = train(model, trainloader, LOCAL_EPOCHS)\n",
    "\n",
    "# Evaluate after training\n",
    "loss_after, acc_after = evaluate(model, valloader)\n",
    "print(f\"  After training:  Loss={loss_after:.4f}, Accuracy={acc_after*100:.2f}%\")\n",
    "print(f\"  Improvement: +{(acc_after - acc_before)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Cell 15: Summary and Key Takeaways\n\n### What We Learned:\n\n1. **Data Partitioning** is the key difference between centralized and federated learning\n   - IID: Data uniformly distributed across clients\n   - Non-IID: Data heterogeneously distributed (realistic scenario)\n\n2. **Flower Framework** makes FL easy:\n   - `FederatedDataset`: Automatic dataset partitioning\n   - `FlowerClient`: Define client behavior\n   - `start_simulation`: Run FL on a single machine\n\n3. **FedAvg Algorithm**:\n   - Server sends global model to clients\n   - Clients train locally\n   - Server averages client models (weighted by data size)\n\n4. **Non-IID Challenge**:\n   - Lower Dirichlet Œ± = more heterogeneous data\n   - Non-IID data can slow convergence and reduce accuracy\n\n### üöÄ Scale Up for Full Experiments\n\nNow that you've verified the pipeline works, try these settings for better results:\n\n```python\n# In Cell 3, change to:\nNUM_CLIENTS = 10\nNUM_ROUNDS = 10\nCLIENTS_PER_ROUND = 5\nBATCH_SIZE = 32\n```\n\nExpected results with full settings:\n- **IID**: ~95%+ accuracy\n- **Non-IID (Œ±=0.5)**: ~90%+ accuracy\n- **Non-IID (Œ±=0.1)**: ~80-85% accuracy\n\n### Next Steps:\n- Try different `DIRICHLET_ALPHA` values (0.1, 0.5, 1.0, 10.0)\n- Increase `NUM_ROUNDS` for better convergence\n- Experiment with different models and optimizers\n- Explore other FL algorithms (FedProx, SCAFFOLD, etc.)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"   FEDERATED LEARNING TUTORIAL COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nYou've learned how to:\")\n",
    "print(\"  ‚úì Partition datasets for federated learning\")\n",
    "print(\"  ‚úì Create FL clients using Flower\")\n",
    "print(\"  ‚úì Run FL simulations\")\n",
    "print(\"  ‚úì Visualize data distribution and training progress\")\n",
    "print(\"\\nHappy Federated Learning! üå∏\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}